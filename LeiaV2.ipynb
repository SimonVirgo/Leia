{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Open and read the config file\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config_data = json.load(config_file)\n",
    "\n",
    "# Retrieve the API key from the config data\n",
    "api_key = config_data['api_key']\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LiquidEarth is a cloud-based solution for the visualization, processing, and analysis of 3D geological data, models, and more. It is relevant to the conversation we were having because it provides a way to visualize, process, and analyze 3D geological data, models, and more.\n"
     ]
    }
   ],
   "source": [
    "chat_engine = index.as_chat_engine()\n",
    "response = chat_engine.chat(\"what is LiquidEarth?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPT 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### create Prompt Template"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from llama_index import Prompt\n",
    "# define custom Prompt\n",
    "TEMPLATE_STR = (\n",
    "    \"You are Leia, the LiquidEarth Intelligent Assistant. You are helping a user with a question about LiquidEarth. You are very smart and friendly and always in a great mood.\\n\"\n",
    "    \"In LiquidEarth, a 'Space' and a 'Project are the same thing. We have provided Documentation on the software and further information below. In some cases the metadata includes a 'Control' Field that points to a UI element in the app associated to the described functionality. this is only for internal use. when describing controls to the user, use descriptions and names from the text, not the 'control' values. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Answer the question for a human to understand. Additionally, return the 'Control' properties in the order of operations in the following form at the end of your response: [[control1], [control2], ...]. Append the list to your response without further comment. If no controls are found, do not comment it. Never include any controls that are not specified in the Metadata Field in the provided documentation. Do not interpret any controls from the text body. If the answer requires multiple steps, describe each step in detail. Given this information, please answer the question: {query_str}\\n\"\n",
    ")\n",
    "QA_TEMPLATE = Prompt(TEMPLATE_STR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(service_context=service_context_gpt4, text_qa_template=QA_TEMPLATE, retriever_mode=\"embedding\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#dirty hack: trying to increase the context size\n",
    "query_engine.retriever._similarity_top_k = 6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "response = query_engine.query(\"hello,how can i create a project and add some data?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Here's how you can create a project and add data in LiquidEarth:\n",
      "\n",
      "**Creating a New Project:**\n",
      "\n",
      "1. Open the server explorer on the left side of your screen.\n",
      "2. Click the Plus button at the bottom of your server explorer list to create a new project.\n",
      "3. If you want to modify basic information and project metadata (like project name and owner), use the Edit Data option in the inspector.\n",
      "    - After setting all required fields, click Save to confirm the information.\n",
      "4. Use the Load Project option in the inspector to load the project into your local workspace (3D Workspace). The project will appear in your 3D workspace and will be listed in the Local Explorer.\n",
      "    - A message will appear in the activity log indicating the loading progress. If you're working online, the project will also be automatically uploaded to the cloud or the remote server you're connected to.\n",
      "\n",
      "The newly created project space in your 3D Workspace will be visualized by a bounding box that covers the extent defined when you created the project. If you didnâ€™t adjust the extent, the standard is set to a cubic extent with a one-meter length for X, Y, and Z.\n",
      "\n",
      "**Importing Data:**\n",
      "\n",
      "1. Select the target space and click on the Import Data button in the bottom left of the Local Explorer.\n",
      "2. This will open the Data Import Wizard which will guide you through the import process for different types of data. The types of data currently supported by LiquidEarth include Meshes (Wavefront OBJ, DXF, OMF, glTF), Boreholes (coming soon), and Volumes (coming soon).\n",
      "3. Choose the type of data you want to import and follow the steps provided in the wizard. After completing the process, the data will be imported into the selected project space. The time this takes can vary depending on the size of the data. A message will appear in the activity log and the loading bar will indicate the importing progress.\n",
      "\n",
      "Once the data is loaded, you can visualize and interact with it using the tools available in LiquidEarth.\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions.\n",
      "\n",
      "[[NULL], [ExplorerDataImporter]]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Response(response=\"I'm an artificial intelligence and don't have feelings, but I'm functioning as expected! Thank you for asking.\", source_nodes=[NodeWithScore(node=TextNode(id_='254ceab8-47f1-4c33-b0e1-3cb2f3f725bd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='71e204eb-d60b-4374-9cce-85886297219b', node_type=None, metadata={}, hash='e1cfbde5e49b0b7d9d1ace99337db6ce97a89788792f23c70c8fcdd1f6bd0ad7')}, hash='62c36937451b513e0c891164fbbea41eb7854312a1b21dc37d8fa74b18e580ae', text='Basics\\n\\n---', start_char_idx=0, end_char_idx=11, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.781250216315416), NodeWithScore(node=TextNode(id_='e2f95d75-00d7-4048-9846-42716d975f78', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e2669401-73fa-4523-ad00-090250e78fcd', node_type=None, metadata={}, hash='9239bf7a67f75d4e9389e950783eccdc955e5ed3389450d5c19e51a02ee5297b')}, hash='54bd3d0783002140c5b1975a4d3cc7cb8b67c0cb3706b1cb0eaa25264bc8bba9', text='Long Description', start_char_idx=0, end_char_idx=16, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7774088917865088), NodeWithScore(node=TextNode(id_='aa71bc56-fb45-4d4b-b85b-48db12ad241f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b1948487-7294-4068-9d07-1812e1a3038a', node_type=None, metadata={}, hash='9239bf7a67f75d4e9389e950783eccdc955e5ed3389450d5c19e51a02ee5297b')}, hash='54bd3d0783002140c5b1975a4d3cc7cb8b67c0cb3706b1cb0eaa25264bc8bba9', text='Long Description', start_char_idx=0, end_char_idx=16, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7773562152856894), NodeWithScore(node=TextNode(id_='eb3e3687-c132-4edb-92f0-f2dbd5a6310f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5d861553-ad31-453b-a5d0-a5aac3818d69', node_type=None, metadata={}, hash='9239bf7a67f75d4e9389e950783eccdc955e5ed3389450d5c19e51a02ee5297b')}, hash='54bd3d0783002140c5b1975a4d3cc7cb8b67c0cb3706b1cb0eaa25264bc8bba9', text='Long Description', start_char_idx=0, end_char_idx=16, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7773414666154485), NodeWithScore(node=TextNode(id_='f4cb9417-ec98-4ef2-81a1-50c1727860b2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c92fed4e-3a60-487f-b503-b3a426c23114', node_type=None, metadata={}, hash='9239bf7a67f75d4e9389e950783eccdc955e5ed3389450d5c19e51a02ee5297b')}, hash='54bd3d0783002140c5b1975a4d3cc7cb8b67c0cb3706b1cb0eaa25264bc8bba9', text='Long Description', start_char_idx=0, end_char_idx=16, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7773414666154485)], metadata={'254ceab8-47f1-4c33-b0e1-3cb2f3f725bd': {}, 'e2f95d75-00d7-4048-9846-42716d975f78': {}, 'aa71bc56-fb45-4d4b-b85b-48db12ad241f': {}, 'eb3e3687-c132-4edb-92f0-f2dbd5a6310f': {}, 'f4cb9417-ec98-4ef2-81a1-50c1727860b2': {}})"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Response(response='The context information provided does not include any specific control properties from the documentation.', source_nodes=[NodeWithScore(node=TextNode(id_='231e7e6b-7b24-48f2-84cf-2cdd81c626e2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='23c7fda5-89da-4807-836a-338ef9e4d60b', node_type=None, metadata={}, hash='4ac1dbe521652d933f25b47af71ba8445e3925649cd40bf4843095ce65dcf733')}, hash='b161860badf44541bc86a3ed070fab56fecc17b2e3963915456dcfa212931116', text='Other Resources\\n\\n---\\n\\nAll Documentation Entries', start_char_idx=0, end_char_idx=47, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7849898990786808), NodeWithScore(node=TextNode(id_='bae2ddf0-57da-42bd-9faa-d9c5a02f0cc8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='be1e6c80-473b-496e-90ae-fdc7f61e4be1', node_type=None, metadata={}, hash='0e7986f6657bc37581cbad16f4d39830af2c4cd2760ce4895ff710073a907914')}, hash='4747d8d7b2057a0ab939cfeb7bc7ea337b292573aeb5ab91984684abd57aff89', text='Advanced Interactions\\n\\nAssigned: Fabian Stamm\\nCategory: Getting Started\\nControl: NULL\\nStatus: In progress\\nlast updated on: November 27, 2022\\n\\nDepending on the selected content, you will have different options to interact with it. This is in most cases done via the inspector.', start_char_idx=0, end_char_idx=275, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7813938339439424)], metadata={'231e7e6b-7b24-48f2-84cf-2cdd81c626e2': {}, 'bae2ddf0-57da-42bd-9faa-d9c5a02f0cc8': {}})"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chat with a prompt template (ToDo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "custom_prompt = Prompt(\"\"\"\\\n",
    "Given a conversation (between Human and Assistant) and a follow up message from Human, \\\n",
    "rewrite the message to be a standalone question that captures all relevant context \\\n",
    "from the conversation.\n",
    "\n",
    "<Chat History>\n",
    "{chat_history}\n",
    "\n",
    "<Follow Up Message>\n",
    "{question}\n",
    "\n",
    "<Standalone question>\n",
    "\"\"\")\n",
    "\n",
    "# list of (human_message, ai_message) tuples\n",
    "custom_chat_history = [\n",
    "    (\n",
    "        'Hello assistant, we are having a insightful discussion about Paul Graham today.',\n",
    "        'Okay, sounds good.'\n",
    "    )\n",
    "]\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    condense_question_prompt=custom_prompt,\n",
    "    chat_history=custom_chat_history,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
