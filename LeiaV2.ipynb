{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Open and read the config file\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config_data = json.load(config_file)\n",
    "\n",
    "# Retrieve the API key from the config data\n",
    "api_key = config_data['api_key']\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# create query engine\n",
    "# it will use lazy embedding\n",
    "queryEngine = index.as_query_engine()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Response(response='\\n1. Select the “Tunneling” option from the “Projects” tab.\\n2. Select the “Create” button to start a new project.\\n3. Select the “Import” button to upload the 3D geological data.\\n4. Select the “Analyze” button to analyze the data.\\n5. Select the “Design” button to design the tunneling project.\\n6. Select the “Simulate” button to simulate the project.\\n7. Select the “Export” button to export the project.', source_nodes=[NodeWithScore(node=TextNode(id_='f15bb996-8bcd-4113-b0fb-e3e87b27debd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2aebf52a-532c-4862-983f-830390801537', node_type=None, metadata={}, hash='e23fdfe472529d28782acc176c21be8a7053496336abdf00326a04e7c106a788')}, hash='97bbeea97343bad39518559157513c9a3250c3b321b872880aba521b8b7e14af', text='LiquidEarth Documentation\\n\\nAll things related to the product - processes, best practices, setup guides, and more!\\n\\nWelcome to LiquidEarth, a cloud-based solution for the visualization, processing, and analysis of 3D geological data, models, and more.\\n\\nThis user manual is here to support you in your work with LiquidEarth. If this is your first time using the app, check out the “Getting Started” section in this manual.\\n\\nIf you need any more help, you can also contact us at\\xa0support@terranigma-solutions.com .', start_char_idx=0, end_char_idx=510, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8046829756481568), NodeWithScore(node=TextNode(id_='a8298179-84fe-4863-a324-a39dde13662d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a686d205-60cc-4c2b-bd78-ef3efe789fcf', node_type=None, metadata={}, hash='b4769adb1fd782b85a525f29ff9f6a9d473d43d83b0abab1e5cbdab7646de7ce')}, hash='8b7eb294ddbd308bbdf19d82eefa9c1599646dd731460b59528570fc468bd0e5', text='Long Description\\n\\nOpen the LiquidEarth user manual and knowledge base.', start_char_idx=0, end_char_idx=70, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8019071163285273)], metadata={'f15bb996-8bcd-4113-b0fb-e3e87b27debd': {}, 'a8298179-84fe-4863-a324-a39dde13662d': {}})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queryEngine.query(\"how do I plan a tunneling project in LiquidEarth? Try finding the Control Fields for each steps of the workflow and append them as a list in order of the operations to your response. only include controls that you are confident exist and are relevant to the question. Only answer this question if you can find the answer in the documentation. If no documentation is found, ask the user to rephrase the question.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Query with a prompt template"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To create a project, open up the server explorer on the left and click the Plus button to create a new project. It will appear at the bottom of your server explorer list. To edit the project's basic information and metadata, use the Edit Data control in the inspector. Once you have set all required fields correctly, save them to accept the information. Then, use the Load Project control in the inspector to load the project into your local workspace (3D Workspace). It will appear in your 3D workspace and listed in the Local Explorer. [[Plus], [Edit Data], [Save], [Load Project]].\n"
     ]
    }
   ],
   "source": [
    "from llama_index import Prompt\n",
    "# define custom Prompt\n",
    "TEMPLATE_STR = (\n",
    "    \"We have provided Documentation on the software and further information below. The Documentation includes Control properties, with the name of the UI element for a certain functionality within the LiquidEarth App .\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Answer the question for a human to understand. Additionally, ONLY where controls are available and, return the control properties in the order of operations in the following form at the end of your response: [[control1], [control2], ...]. Never include any controls that are empty or not specifically included as Control properties in the provided documentation. Given this information, please answer the question: {query_str}\\n\"\n",
    ")\n",
    "QA_TEMPLATE = Prompt(TEMPLATE_STR)\n",
    "\n",
    "# Configure query engine\n",
    "query_engine = index.as_query_engine(text_qa_template=QA_TEMPLATE)\n",
    "\n",
    "# Execute query\n",
    "response = query_engine.query(\"how can I create a project?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "response = query_engine.query(\"how to install liquidEarth on my quest?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chat with the index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LiquidEarth is a cloud-based solution for the visualization, processing, and analysis of 3D geological data, models, and more. It is relevant to the conversation we were having because it provides a way to visualize, process, and analyze 3D geological data, models, and more.\n"
     ]
    }
   ],
   "source": [
    "chat_engine = index.as_chat_engine()\n",
    "response = chat_engine.chat(\"what is LiquidEarth?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LiquidEarth is a cloud-based solution for the visualization, processing, and analysis of 3D geological data, models, and more. It is relevant to the conversation because it provides a way to visualize, process, and analyze 3D geological data, models, and more.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"what was my previous question?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "response = chat_engine.chat(\"can you rephrase my previous question?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LiquidEarth is a cloud-based solution for the visualization, processing, and analysis of 3D geological data, models, and more. It is relevant to the conversation because it provides a way to visualize, process, and analyze 3D geological data, models, and more.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What can I do if I need help with LiquidEarth, the cloud-based solution for the visualization, processing, and analysis of 3D geological data, models, and more?\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"please repeat my previous question backwards\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "chat_engine.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chat with a prompt template (ToDo)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "custom_prompt = Prompt(\"\"\"\\\n",
    "Given a conversation (between Human and Assistant) and a follow up message from Human, \\\n",
    "rewrite the message to be a standalone question that captures all relevant context \\\n",
    "from the conversation.\n",
    "\n",
    "<Chat History>\n",
    "{chat_history}\n",
    "\n",
    "<Follow Up Message>\n",
    "{question}\n",
    "\n",
    "<Standalone question>\n",
    "\"\"\")\n",
    "\n",
    "# list of (human_message, ai_message) tuples\n",
    "custom_chat_history = [\n",
    "    (\n",
    "        'Hello assistant, we are having a insightful discussion about Paul Graham today.',\n",
    "        'Okay, sounds good.'\n",
    "    )\n",
    "]\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    condense_question_prompt=custom_prompt,\n",
    "    chat_history=custom_chat_history,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPT 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(service_context=service_context_gpt4, text_qa_template=QA_TEMPLATE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "response = query_engine.query(\"how can I create a project?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a new project in the LiquidEarth App, follow these steps:\n",
      "\n",
      "1. Open the server explorer which is located on the left side of the interface.\n",
      "2. Click on the Plus button. This will create a new project which will appear at the bottom of your server explorer list.\n",
      "3. Optionally, you can edit the basic information and project metadata such as the project name and owner. To do this, use the Edit Data option in the inspector. Once you have set all required fields correctly, click Save to accept the information.\n",
      "4. To load the project into your local workspace (3D Workspace), use the Load Project option in the inspector. The project will appear in your 3D workspace and will be listed in the Local Explorer. If you are working online, the project will also be automatically uploaded to the cloud or the remote server you are connected to.\n",
      "\n",
      "The control properties in the order of operations are: [[Server Explorer], [Plus Button], [Edit Data], [Save], [Load Project]].\n"
     ]
    }
   ],
   "source": [
    "print(response)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To visualize your Leapfrog geological model in the LiquidEarth app, you would first need to import your model into the app. Unfortunately, the provided documentation does not specify the exact steps or controls to import and visualize a Leapfrog geological model. \n",
      "\n",
      "However, once your model is imported, you can use the Real-Scale View feature to visualize your model in real scale. This feature allows you to place your view in the model or on top of a rendered topography. If you're using AR, it can also use your GPS to create a localized real-world overlay of your model.\n",
      "\n",
      "If you're new to the app, it's recommended to check out the “Getting Started” section in the user manual. If you need further assistance, you can contact support at support@terranigma-solutions.com.\n",
      "\n",
      "Since the documentation does not provide specific control properties for this process, I'm unable to provide them in the requested format.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"i want to visualize my leapfrog geological model. how can I do that?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
